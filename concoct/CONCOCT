#!/usr/bin/env python
from __future__ import division

import sys
import logging

import pandas as p

from itertools import chain

from sklearn.decomposition import PCA
from sklearn.mixture import GMM

import multiprocessing

from concoct.output import Output
from concoct.parser import arguments
from concoct.cluster import cluster
from concoct.input import load_composition, load_coverage

def main(comp_file, cov_file, kmer_len, threshold, 
         read_length, clusters_range, cov_range, 
         split_pca, inits, iters, outdir, pipe,
         max_n_processors, pca_components, args=None):

    # Main node is if we're
    # 1. using MPI and are rank 0 
    # or 
    # 2. if we are not using MPI
    main_node = ((max_n_processors.use_mpi and 
                  max_n_processors.rank==0) or 
                 not max_n_processors.use_mpi)

    if main_node:
        Output(outdir,args)

        composition, contig_lengths, threshold_filter = \
            load_composition(comp_file, kmer_len, threshold)
        cov, cov_range = load_coverage(cov_file, cov_range, contig_lengths)

        joined = composition.join(
            cov.ix[:,cov_range[0]:cov_range[1]],how="inner")
        if split_pca:
            cov_pca = PCA(n_components=pca_components[0]).fit(
                cov[threshold_filter].ix[:,cov_range[0]:cov_range[1]])
            transform_filter_cov = cov_pca.transform(
                cov[threshold_filter].ix[:,cov_range[0]:cov_range[1]])

            transform_filter_cov = p.DataFrame(transform_filter_cov,
                                               index=cov[threshold_filter].index)
            transform_filter_cov = transform_filter_cov.rename(
                columns=lambda x: 'cov_'+str(x))

            comp_pca = PCA(n_components=pca_components[1]).fit(
                composition[threshold_filter])
            transform_filter_comp = comp_pca.transform(composition[threshold_filter])
            transform_filter_comp = p.DataFrame(transform_filter_comp,
                                                index=composition[threshold_filter].index)
            transform_filter_comp = transform_filter_comp.rename(
                columns=lambda x: 'comp_'+str(x))
            transform_filter = transform_filter_comp.join(
                transform_filter_cov, how='inner')
        else:
            #PCA on the contigs that have kmer count greater than threshold
            pca = PCA(n_components=pca_components).fit(joined[threshold_filter])
            transform_filter = pca.transform(joined[threshold_filter])

        Output.write_original_data(joined[threshold_filter],threshold)
        Output.write_pca(transform_filter,
                         threshold,cov[threshold_filter].index)
        logging.info('PCA transformed data.')
        cv_type='full'
        cluster_args = []
        for c in clusters_range:
            cluster_args.append((c,cv_type,inits,iters,transform_filter))

    #This code should be executed by all threads
    if max_n_processors.use_mpi:
        if max_n_processors.rank != 0:
            cluster_args = []
        cluster_args = max_n_processors.comm.bcast(cluster_args, root=0)
        result = map(cluster,cluster_args[max_n_processors.rank::max_n_processors.size])
        #Gather all results to root process again
        results = max_n_processors.comm.gather(result, root=0)
        if max_n_processors.rank == 0:
            results = list(chain(*results))
    
    else:
        pool = multiprocessing.Pool(processes=max_n_processors.size)
        results = pool.map(cluster,cluster_args)

    if main_node:
        bics = [(r[0],r[1]) for r in results]
        Output.write_bic(bics)
        min_bic,optimal_c = min(bics,key=lambda x: x[0])
        gmm = GMM(n_components=optimal_c,covariance_type=cv_type,n_init=inits,
                  n_iter=iters).fit(transform_filter)
    

        if split_pca:
            # Transform both unfiltered datasets separately before joining
            transform_comp = comp_pca.transform(composition)
            transform_cov = cov_pca.transform(cov)
            transform_comp = p.DataFrame(transform_comp,
                                         index=composition.index)
            transform_cov = p.DataFrame(transform_cov,
                                        index=cov.index)
            # Renaming is necessary so no columns have the same name
            transform_comp = transform_comp.rename(
                columns = lambda x: 'comp_'+str(x))
            transform_cov = transform_cov.rename(
                columns = lambda x: 'cov_'+str(x))
            joined_transform = transform_comp.join(
                transform_cov, how='inner')

            joined["clustering"] = gmm.predict(joined_transform)
                        
        else:
            joined["clustering"] = gmm.predict(pca.transform(joined))
            Output.write_cluster_means(pca.inverse_transform(gmm.means_),
                                       threshold,c)
        # Covariance matrix is three dimensional if full
        if cv_type == 'full':
            for i,v in enumerate(gmm.covars_):
                if not split_pca:
                    Output.write_cluster_variance(pca.inverse_transform(v),
                                                  threshold,i)
                Output.write_cluster_pca_variances(v,threshold,i)
        else:
            # Not implemented yet
            pass
            
        Output.write_clustering(joined,threshold_filter,threshold,c,pipe)
        Output.write_cluster_pca_means(gmm.means_,threshold,c)
            
        pp = gmm.predict_proba(transform_filter)
    
        Output.write_cluster_responsibilities(
            pp,
            threshold,c)
        logging.info("CONCOCT Finished")


        
if __name__=="__main__":
    args = arguments()
    if args.split_pca:
        cov = args.coverage_percentage_pca/100.0
        comp = args.composition_percentage_pca/100.0
        pca_components = (cov,comp)
                          
    else:
        pca_components = args.total_percentage_pca/100.0

    results = main(args.composition_file, 
                   args.coverage_file,
                   args.kmer_length, 
                   args.limit_kmer_count, 
                   args.read_length, 
                   args.clusters, 
                   args.coverage_file_column_names, 
                   args.split_pca, 
                   args.executions, 
                   args.iterations, 
                   args.basename, 
                   args.pipe,
                   args.max_n_processors,
                   pca_components,
                   args)
    if (args.max_n_processors.use_mpi and args.max_n_processors.rank==0) or not args.max_n_processors.use_mpi:
        print >> sys.stderr, "CONCOCT Finished, the log shows how it went."
